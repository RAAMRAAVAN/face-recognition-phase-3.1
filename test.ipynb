{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from gae.model import GCNModelVAE\n",
    "\n",
    "from gae.optimizer import loss_function\n",
    "from gae.utils import load_data, mask_test_edges, preprocess_graph, get_roc_score\n",
    "\n",
    "import import_ipynb\n",
    "from gaemain import gae_for\n",
    "\n",
    "from scipy.stats.stats import pearsonr  \n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N=7\n",
    "# N2=(N-1)*10 + N\n",
    "# image_path=\"./orl_dataset/person\"+str(N)+\"/train_images/\"+str(N2)+\"_\"+str(N)+\".jpg\"\n",
    "# Z=gae_for(image_path)\n",
    "# Z=Z.detach().numpy()\n",
    "# # print(N,N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "testSets=[]\n",
    "for person in range(1,5):\n",
    "    path=\"./orl_dataset/person\"+str(person)+\"/test_image/\"\n",
    "    files=os.listdir(path)\n",
    "    count=0\n",
    "    for image in files:\n",
    "        image_path=path+image\n",
    "        # print(image_path)\n",
    "        count=count+1\n",
    "        Z=gae_for(image_path)\n",
    "        # Z=Z.detach().numpy() #convert to Numpy array\n",
    "        Z = pd.DataFrame(Z) #convert to a dataframe\n",
    "        testSets.append(Z)\n",
    "        csv_path=\"./orl_dataset/person\"+str(person)+\"/latent_representation_2/testfile\"+str(count)+\".csv\"\n",
    "        Z.to_csv(csv_path,index=False) #save to file\n",
    "print(len(testSets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# testSets=[]\n",
    "# ind=0\n",
    "# for person in range(1,10):\n",
    "#     tests=glob.glob(\"./orl_dataset/person\"+str(person)+\"/latent_representation_2/*.csv\")\n",
    "#     for test in tests: #for eacg file\n",
    "#         testSets.append(np.loadtxt(test,delimiter=','))  #sign[ind]= content of file, seperated by comma\n",
    "#         testSets[ind]=testSets[ind][1:]\n",
    "#         ind+=1\n",
    "#     print(len(testSets))\n",
    "# print(tests)\n",
    "# print(len(testSets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson= 34\n",
      "cosine= 34\n",
      "c_dist= 34\n",
      "matched with= 4\n",
      "index= 1\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 85\n",
      "cosine= 85\n",
      "c_dist= 85\n",
      "matched with= 9\n",
      "index= 1\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 51\n",
      "cosine= 51\n",
      "c_dist= 51\n",
      "matched with= 6\n",
      "index= 1\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 73\n",
      "cosine= 73\n",
      "c_dist= 73\n",
      "matched with= 8\n",
      "index= 2\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 11\n",
      "cosine= 11\n",
      "c_dist= 11\n",
      "matched with= 2\n",
      "index= 2\n",
      "pearson= 54\n",
      "cosine= 54\n",
      "c_dist= 54\n",
      "matched with= 6\n",
      "index= 2\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 6\n",
      "cosine= 6\n",
      "c_dist= 6\n",
      "matched with= 1\n",
      "index= 3\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 56\n",
      "cosine= 56\n",
      "c_dist= 56\n",
      "matched with= 6\n",
      "index= 3\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 80\n",
      "cosine= 80\n",
      "c_dist= 80\n",
      "matched with= 9\n",
      "index= 3\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 83\n",
      "cosine= 83\n",
      "c_dist= 83\n",
      "matched with= 9\n",
      "index= 4\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 26\n",
      "cosine= 26\n",
      "c_dist= 26\n",
      "matched with= 3\n",
      "index= 4\n",
      "\t\t\t\tthis is wrong\n",
      "pearson= 87\n",
      "cosine= 87\n",
      "c_dist= 87\n",
      "matched with= 9\n",
      "index= 4\n",
      "\t\t\t\tthis is wrong\n",
      "1\n",
      "Total Test Case: 12\n",
      "Average Accuracy: 0.9345238095238096\n",
      "Recognition Rate: 0.08333333333333333\n",
      "Average Precision: 0.08333333333333333\n",
      "Average Recall: 0.08333333333333333\n",
      "Average F0.5 Score: 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "acc=[]\n",
    "avg_p=[]\n",
    "avg_recall=[]\n",
    "avg_fScore=[]\n",
    "betaSquare=0.5*0.5\n",
    "r_rate=0 #recognition rate\n",
    "pr_rate=0 #recognition rate\n",
    "acc=[]\n",
    "\n",
    "# files = glob.glob('./orl_dataset/latent1/*.csv')\n",
    "sign=[]  #15*null\n",
    "\n",
    "index=0\n",
    "count=1\n",
    "\n",
    "for testSet in testSets:\n",
    "  data = []\n",
    "  test=[]\n",
    "  # for file in files:\n",
    "  TP=0\n",
    "  TN=0\n",
    "  FP=0\n",
    "  FN=0\n",
    "  tdata=testSet\n",
    "\n",
    "  # print(\"Z=\",type(Z))\n",
    "  dist=[]\n",
    "  pearson_dist=[]\n",
    "  cosine_dist=[]\n",
    "  c_dist=[]\n",
    "\n",
    "  orig_path=\"./orl_dataset/\"\n",
    "  files=os.listdir(orig_path)\n",
    "  tests=[]\n",
    "  # count=0\n",
    "  for file in files:\n",
    "    # path=file + '/latent_representation/'\n",
    "    tests=glob.glob(orig_path + file + '/latent_representation/*.csv')\n",
    "\n",
    "    sign=[None]*15  #15*null\n",
    "    ind=0\n",
    "    # print(\"files=\",len(files))\n",
    "    for test in tests: #for eacg file\n",
    "      sign[ind]=np.loadtxt(test,delimiter=',')  #sign[ind]= content of file, seperated by comma\n",
    "      sign[ind]=sign[ind][1:]\n",
    "      ind+=1\n",
    "\n",
    "    # print(\"test \",tests)\n",
    "    # print(\"sign[0]=\",sign[0])\n",
    "\n",
    "    for ele in sign:\n",
    "      if ele is None:\n",
    "        break\n",
    "      dist.append(np.linalg.norm(ele-tdata))\n",
    "      cosine_dist.append(1 - spatial.distance.cosine(np.array(tdata).flatten() ,np.array(ele).flatten()))\n",
    "      pearson_dist.append(pearsonr(np.array(tdata).flatten() ,np.array(ele).flatten())[0])\n",
    "      c_dist.append(pearsonr(np.array(tdata).flatten() ,np.array(ele).flatten())[0])\n",
    "\n",
    "  # min_ind=dist.index(min(dist))\n",
    "  # print(\"len cosine_dist\",len(cosine_dist))\n",
    "  # print(\"pearson_dist\",pearson_dist)\n",
    "  max_ind=pearson_dist.index(max(pearson_dist))\n",
    "  max_cosine=cosine_dist.index(max(cosine_dist))\n",
    "  max_c_dist=c_dist.index(max(c_dist))\n",
    "  print(\"pearson=\",max_ind)\n",
    "  print(\"cosine=\",max_cosine)\n",
    "  print(\"c_dist=\",max_c_dist)\n",
    "  print(\"matched with=\", max_c_dist//10 + 1)\n",
    "  print(\"index=\", index//3 + 1)\n",
    "  if(index//3 + 1 != max_c_dist//10 + 1):\n",
    "    print(\"\\t\\t\\t\\tthis is wrong\")\n",
    "    TP=0\n",
    "    TN=13\n",
    "    FP=1\n",
    "    FP=1\n",
    "  elif(index//3 +1 == max_c_dist//10 + 1):\n",
    "    r_rate+=1\n",
    "    TP=1\n",
    "    TN=14\n",
    "    FN=0\n",
    "    FP=0\n",
    "  #Measures\n",
    "\n",
    "  Accuracy = (TP + TN )/ (TP + TN + FP + FN) #(all correct / all)\n",
    "  Misclassification = (FP + FN )/ (TP + TN + FP + FN) #(all incorrect / all)\n",
    "  Precision  = TP / (TP + FP) #(true positives / predicted positives)\n",
    "  deno=TP+FP\n",
    "  Sensitivity   = TP / (deno) #aka Recall (true positives / all actual positives)\n",
    "  Specificity  =TN / (TN + FP) #(true negatives / all actual negatives)\n",
    "  F1_deno=(Precision+Sensitivity)\n",
    "  if(F1_deno==0):\n",
    "    F1_Score=0\n",
    "  else:\n",
    "    F1_Score=(1+betaSquare)*((Precision*Sensitivity)/(betaSquare*F1_deno))\n",
    "  # print(\"\\nAccuracy: {}\\nMisclassification: {}\\nPrecision: {}\\nSensitivity: {}\\nSpecificity: {}\\nF1_Score: {}\\n\".format(Accuracy,Misclassification,Precision,Sensitivity,Specificity,F1_Score))\n",
    "  acc.append(Accuracy)\n",
    "  avg_p.append(Precision)\n",
    "  avg_recall.append(Sensitivity)\n",
    "  avg_fScore.append(F1_Score)\n",
    "  index=index+1\n",
    "print(r_rate)\n",
    "print(\"Total Test Case: {}\\nAverage Accuracy: {}\\nRecognition Rate: {}\\nAverage Precision: {}\\nAverage Recall: {}\\nAverage F0.5 Score: {}\".format(len(acc),(sum(acc)/len(acc)),r_rate/len(acc),(sum(avg_p)/len(avg_p)),(sum(avg_recall)/len(avg_recall)),(sum(avg_fScore)/len(avg_fScore))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aadfbdf25e6c44ec54c3392f55309ee547c7867a1cc44e79bd77663d13a5dcc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
